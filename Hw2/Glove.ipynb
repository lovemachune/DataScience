{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, LSTM, Conv2D\n",
    "from keras.models import Model, Sequential\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_split(mystring):\n",
    "    str_split = []\n",
    "    nltk_stopwords= nltk.corpus.stopwords.words('english')\n",
    "    for tmp in mystring:\n",
    "        tmp = tmp.lower()\n",
    "        #punct_token = wordpunct_tokenize(tmp)\n",
    "        tmp = re.sub('[^a-zA-Z0-9\\s\\?\\!]+', '', tmp)\n",
    "        tmp = tmp.replace('!', ' !')\n",
    "        tmp = tmp.replace('?', ' ?')\n",
    "        tmp = tmp.split(' ')\n",
    "        '''\n",
    "        punct_token = [word for word in punct_token if word not in nltk_stopwords]\n",
    "        #remove string.punctuation\n",
    "        punct_token = [word for word in punct_token if word not in string.punctuation]\n",
    "        '''\n",
    "        while True:\n",
    "            if '' not in tmp:\n",
    "                break\n",
    "            tmp.remove('')\n",
    "        while True:\n",
    "            if 'the' not in tmp:\n",
    "                break\n",
    "            tmp.remove('the')\n",
    "        '''\n",
    "        while True:\n",
    "            if 'and' not in tmp:\n",
    "                break\n",
    "            tmp.remove('and')\n",
    "        while True:\n",
    "            if 'of' not in tmp:\n",
    "                break\n",
    "            tmp.remove('of')\n",
    "        while True:\n",
    "            if 'is' not in tmp:\n",
    "                break\n",
    "            tmp.remove('is')\n",
    "        while True:\n",
    "            if 'are' not in tmp:\n",
    "                break\n",
    "            tmp.remove('are')\n",
    "        '''\n",
    "        str_split.append(tmp)\n",
    "    return str_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rtes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import string\n",
    "from nltk import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_DIR = './'\n",
    "MAX_SEQUENCE_LENGTH = 50\n",
    "MAX_NB_WORDS = 10000\n",
    "EMBEDDING_DIM = 100\n",
    "NUM_LSTM_UNITS = 512\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'), encoding='utf8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv(\"train.csv\")\n",
    "data = all_data['Headline']\n",
    "label = all_data['Label']\n",
    "my_split = word_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(my_split)\n",
    "sequences = tokenizer.texts_to_sequences(my_split)\n",
    "word_index = tokenizer.word_index\n",
    "x = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = min(MAX_NB_WORDS, len(word_index))+1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NB_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "cnn = Sequential()\n",
    "xx = Conv1D(NUM_LSTM_UNITS, 4, activation='relu')(embedded_sequences)\n",
    "xx = MaxPooling1D(2)(xx)\n",
    "xx = Dropout(0.2)(xx)\n",
    "xx = Conv1D(NUM_LSTM_UNITS, 4, activation='relu')(xx)\n",
    "xx = MaxPooling1D(2)(xx)\n",
    "xx = Dropout(0.2)(xx)\n",
    "l1 = LSTM(NUM_LSTM_UNITS, input_shape=(MAX_SEQUENCE_LENGTH, NUM_LSTM_UNITS), return_sequences=True)\n",
    "l2 = LSTM(NUM_LSTM_UNITS, return_sequences=False)\n",
    "xx = l1(xx)\n",
    "xx = l2(xx)\n",
    "predictions = Dense(units=1, activation='linear')(xx)\n",
    "model = Model(inputs=sequence_input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 50, 100)           1000100   \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 47, 512)           205312    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 23, 512)           0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 23, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 20, 512)           1049088   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 10, 512)           0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 10, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 10, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 6,453,413\n",
      "Trainable params: 5,453,313\n",
      "Non-trainable params: 1,000,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.MeanSquaredError(),\n",
    "              optimizer=keras.optimizers.SGD())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, label, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 12s 211ms/step - loss: 0.3404 - val_loss: 0.4777\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train ,batch_size=32 ,epochs=1,validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f10c27bef0>,\n",
       " <matplotlib.lines.Line2D at 0x1f10c27bf98>]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.plot(train_loss,'r', val_loss, 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.6471453]\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"test.csv\")\n",
    "data = test_data['Headline']\n",
    "label = test_data['Label']\n",
    "test_split = word_split(data)\n",
    "sequences = tokenizer.texts_to_sequences(test_split)\n",
    "x = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "y_pre = model.predict(x)\n",
    "print(y_pre[0])\n",
    "b = np.arange(1, y_pre.shape[0]+1).reshape(y_pre.shape[0], 1)\n",
    "y_pre = np.append(b, y_pre, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('output.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['ID','Label'])\n",
    "    writer.writerows(y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rtes\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\rtes\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ./mymodel_0.445/assets\n"
     ]
    }
   ],
   "source": [
    "#model.save('./mymodel_0.445/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = keras.models.load_model('./mymodel_0.445/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.3372777]\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"test.csv\")\n",
    "data = test_data['Headline']\n",
    "label = test_data['Label']\n",
    "test_split = word_split(data)\n",
    "sequences = tokenizer.texts_to_sequences(test_split)\n",
    "x = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "y_pre = mm.predict(x)\n",
    "print(y_pre[0])\n",
    "b = np.arange(1, y_pre.shape[0]+1).reshape(y_pre.shape[0], 1)\n",
    "y_pre = np.append(b, y_pre, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 50, 100)           1000100   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 47, 512)           205312    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 23, 512)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 23, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 20, 512)           1049088   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 10, 512)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 10, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 6,453,413\n",
      "Trainable params: 6,453,413\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
