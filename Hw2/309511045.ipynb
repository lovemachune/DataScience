{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, LSTM, Conv2D, Bidirectional\n",
    "from keras.models import Model, Sequential\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_split(mystring):\n",
    "    str_split = []\n",
    "    #nltk_stopwords= nltk.corpus.stopwords.words('english')\n",
    "    for tmp in mystring:\n",
    "        tmp = tmp.lower()\n",
    "        #punct_token = wordpunct_tokenize(tmp)\n",
    "        tmp = re.sub('[^a-zA-Z0-9\\s\\?\\!]+', '', tmp)\n",
    "        tmp = tmp.replace('!', ' !')\n",
    "        tmp = tmp.replace('?', ' ?')\n",
    "        tmp = tmp.split(' ')\n",
    "        while True:\n",
    "            if '' not in tmp:\n",
    "                break\n",
    "            tmp.remove('')\n",
    "        while True:\n",
    "            if 'the' not in tmp:\n",
    "                break\n",
    "            tmp.remove('the')\n",
    "        while True:\n",
    "            if 'and' not in tmp:\n",
    "                break\n",
    "            tmp.remove('and')\n",
    "        while True:\n",
    "            if 'of' not in tmp:\n",
    "                break\n",
    "            tmp.remove('of')\n",
    "        '''\n",
    "        while True:\n",
    "            if 'is' not in tmp:\n",
    "                break\n",
    "            tmp.remove('is')\n",
    "        while True:\n",
    "            if 'are' not in tmp:\n",
    "                break\n",
    "            tmp.remove('are')\n",
    "        '''\n",
    "        str_split.append(tmp)\n",
    "    return str_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_DIR = './'\n",
    "MAX_SEQUENCE_LENGTH = 50\n",
    "MAX_NB_WORDS = 10000\n",
    "EMBEDDING_DIM = 100\n",
    "NUM_LSTM_UNITS = 512\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'), encoding='utf8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv(\"train.csv\")\n",
    "data = all_data['Headline']\n",
    "label = all_data['Label']\n",
    "my_split = word_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(my_split)\n",
    "sequences = tokenizer.texts_to_sequences(my_split)\n",
    "word_index = tokenizer.word_index\n",
    "x = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = min(MAX_NB_WORDS, len(word_index))+1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NB_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = keras.models.load_model('./mymodel_0.445/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.3372777]\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"test.csv\")\n",
    "data = test_data['Headline']\n",
    "label = test_data['Label']\n",
    "test_split = word_split(data)\n",
    "sequences = tokenizer.texts_to_sequences(test_split)\n",
    "x = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "y_pre = mm.predict(x)\n",
    "print(y_pre[0])\n",
    "b = np.arange(1, y_pre.shape[0]+1).reshape(y_pre.shape[0], 1).astype('int32')\n",
    "y_pre = np.append(b, y_pre, axis=1).astype(object)\n",
    "for i in range(len(y_pre)):\n",
    "    y_pre[i][0] = int(y_pre[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['ID','Label'])\n",
    "    writer.writerows(y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID     Label\n",
      "0      1  2.337278\n",
      "1      2  2.964703\n",
      "2      3  2.684707\n",
      "3      4  2.922065\n",
      "4      5  2.455397\n",
      "..   ...       ...\n",
      "222  223  3.060324\n",
      "223  224  2.522440\n",
      "224  225  2.865470\n",
      "225  226  2.824675\n",
      "226  227  2.668736\n",
      "\n",
      "[227 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.           2.33727765]\n",
      " [  2.           2.96470284]\n",
      " [  3.           2.6847074 ]\n",
      " [  4.           2.92206478]\n",
      " [  5.           2.45539689]\n",
      " [  6.           2.97061849]\n",
      " [  7.           2.58647394]\n",
      " [  8.           2.79769993]\n",
      " [  9.           2.77798533]\n",
      " [ 10.           2.42695355]\n",
      " [ 11.           3.27664232]\n",
      " [ 12.           3.04154325]\n",
      " [ 13.           2.89882112]\n",
      " [ 14.           2.77106595]\n",
      " [ 15.           2.96575713]\n",
      " [ 16.           2.92711282]\n",
      " [ 17.           3.32004571]\n",
      " [ 18.           2.74923491]\n",
      " [ 19.           2.68168068]\n",
      " [ 20.           2.736027  ]\n",
      " [ 21.           2.99287391]\n",
      " [ 22.           3.0937252 ]\n",
      " [ 23.           3.36100125]\n",
      " [ 24.           2.96078277]\n",
      " [ 25.           2.87634826]\n",
      " [ 26.           2.89174509]\n",
      " [ 27.           3.17974687]\n",
      " [ 28.           3.03055286]\n",
      " [ 29.           2.83711433]\n",
      " [ 30.           2.54342747]\n",
      " [ 31.           2.76695991]\n",
      " [ 32.           3.02402472]\n",
      " [ 33.           2.84787703]\n",
      " [ 34.           2.46678901]\n",
      " [ 35.           2.72022367]\n",
      " [ 36.           2.31628752]\n",
      " [ 37.           3.04871202]\n",
      " [ 38.           2.62567878]\n",
      " [ 39.           3.01482916]\n",
      " [ 40.           3.45500827]\n",
      " [ 41.           3.01416135]\n",
      " [ 42.           2.49350333]\n",
      " [ 43.           3.11698461]\n",
      " [ 44.           2.89077878]\n",
      " [ 45.           2.8905561 ]\n",
      " [ 46.           2.61657214]\n",
      " [ 47.           2.45249748]\n",
      " [ 48.           2.65571332]\n",
      " [ 49.           2.91560793]\n",
      " [ 50.           3.18892694]\n",
      " [ 51.           2.81780052]\n",
      " [ 52.           2.86139035]\n",
      " [ 53.           2.71182179]\n",
      " [ 54.           3.22726464]\n",
      " [ 55.           2.88109422]\n",
      " [ 56.           3.4207232 ]\n",
      " [ 57.           2.71208739]\n",
      " [ 58.           3.03654504]\n",
      " [ 59.           2.55813098]\n",
      " [ 60.           3.12588859]\n",
      " [ 61.           2.60741425]\n",
      " [ 62.           2.55918622]\n",
      " [ 63.           2.85237479]\n",
      " [ 64.           2.94630527]\n",
      " [ 65.           2.76129031]\n",
      " [ 66.           3.08971524]\n",
      " [ 67.           2.40755939]\n",
      " [ 68.           2.37382078]\n",
      " [ 69.           2.67886019]\n",
      " [ 70.           2.92100692]\n",
      " [ 71.           3.00645614]\n",
      " [ 72.           3.11332154]\n",
      " [ 73.           2.80478096]\n",
      " [ 74.           2.66311622]\n",
      " [ 75.           2.85461187]\n",
      " [ 76.           2.78498149]\n",
      " [ 77.           2.63810086]\n",
      " [ 78.           3.00655723]\n",
      " [ 79.           2.93582726]\n",
      " [ 80.           2.61095834]\n",
      " [ 81.           2.82566714]\n",
      " [ 82.           2.68748403]\n",
      " [ 83.           2.85490298]\n",
      " [ 84.           2.93691921]\n",
      " [ 85.           2.74718451]\n",
      " [ 86.           2.64311886]\n",
      " [ 87.           2.77785993]\n",
      " [ 88.           2.92653728]\n",
      " [ 89.           2.43956804]\n",
      " [ 90.           2.42992711]\n",
      " [ 91.           2.95427108]\n",
      " [ 92.           2.59550571]\n",
      " [ 93.           2.78639722]\n",
      " [ 94.           2.58678079]\n",
      " [ 95.           2.89777136]\n",
      " [ 96.           2.96057296]\n",
      " [ 97.           3.13086963]\n",
      " [ 98.           2.65821838]\n",
      " [ 99.           3.52214122]\n",
      " [100.           2.52618146]\n",
      " [101.           3.11954093]\n",
      " [102.           2.68251896]\n",
      " [103.           2.59947038]\n",
      " [104.           2.76646495]\n",
      " [105.           2.98656297]\n",
      " [106.           2.60949588]\n",
      " [107.           2.90935493]\n",
      " [108.           2.84767151]\n",
      " [109.           2.66803145]\n",
      " [110.           2.7579906 ]\n",
      " [111.           3.29963207]\n",
      " [112.           3.10707307]\n",
      " [113.           2.93255639]\n",
      " [114.           2.67579293]\n",
      " [115.           2.96955371]\n",
      " [116.           2.79583287]\n",
      " [117.           2.37643647]\n",
      " [118.           2.94394755]\n",
      " [119.           2.79347968]\n",
      " [120.           3.01571631]\n",
      " [121.           2.8953886 ]\n",
      " [122.           2.70115018]\n",
      " [123.           2.75639129]\n",
      " [124.           3.18611598]\n",
      " [125.           2.7619102 ]\n",
      " [126.           3.13783097]\n",
      " [127.           2.90038371]\n",
      " [128.           2.5537684 ]\n",
      " [129.           2.8967483 ]\n",
      " [130.           2.83965898]\n",
      " [131.           2.74721837]\n",
      " [132.           2.63463926]\n",
      " [133.           3.10589671]\n",
      " [134.           2.69236827]\n",
      " [135.           2.82534766]\n",
      " [136.           2.95387816]\n",
      " [137.           2.60652423]\n",
      " [138.           2.80317855]\n",
      " [139.           2.41043878]\n",
      " [140.           2.64952588]\n",
      " [141.           2.91197181]\n",
      " [142.           2.89012074]\n",
      " [143.           3.07997632]\n",
      " [144.           2.91031718]\n",
      " [145.           2.49972463]\n",
      " [146.           2.83291435]\n",
      " [147.           2.99523473]\n",
      " [148.           2.81454182]\n",
      " [149.           2.73554564]\n",
      " [150.           2.92076612]\n",
      " [151.           3.32986999]\n",
      " [152.           2.73829246]\n",
      " [153.           3.56692505]\n",
      " [154.           2.94799399]\n",
      " [155.           2.94237995]\n",
      " [156.           3.08889127]\n",
      " [157.           2.9589684 ]\n",
      " [158.           2.7735064 ]\n",
      " [159.           2.89756846]\n",
      " [160.           2.51095176]\n",
      " [161.           2.9140079 ]\n",
      " [162.           2.89124227]\n",
      " [163.           3.07121396]\n",
      " [164.           2.66756964]\n",
      " [165.           2.80180812]\n",
      " [166.           2.54165196]\n",
      " [167.           2.93051219]\n",
      " [168.           2.90639281]\n",
      " [169.           2.89825654]\n",
      " [170.           2.87991357]\n",
      " [171.           2.7354238 ]\n",
      " [172.           2.76271701]\n",
      " [173.           2.71684909]\n",
      " [174.           2.78087926]\n",
      " [175.           3.60768056]\n",
      " [176.           3.03872299]\n",
      " [177.           2.66429448]\n",
      " [178.           2.53819489]\n",
      " [179.           3.02700996]\n",
      " [180.           2.96314311]\n",
      " [181.           2.45873952]\n",
      " [182.           3.03086638]\n",
      " [183.           3.01173067]\n",
      " [184.           2.907444  ]\n",
      " [185.           2.79094815]\n",
      " [186.           2.38064933]\n",
      " [187.           2.67822218]\n",
      " [188.           3.04016328]\n",
      " [189.           3.59830856]\n",
      " [190.           3.29718471]\n",
      " [191.           2.54176021]\n",
      " [192.           3.6304419 ]\n",
      " [193.           2.35583138]\n",
      " [194.           2.89695835]\n",
      " [195.           2.86512685]\n",
      " [196.           2.72128057]\n",
      " [197.           3.48674178]\n",
      " [198.           3.05336976]\n",
      " [199.           2.67665124]\n",
      " [200.           3.5461297 ]\n",
      " [201.           2.87566924]\n",
      " [202.           2.94195652]\n",
      " [203.           2.84883094]\n",
      " [204.           3.31969094]\n",
      " [205.           2.81094623]\n",
      " [206.           2.68503547]\n",
      " [207.           2.5343821 ]\n",
      " [208.           2.69223332]\n",
      " [209.           2.75328851]\n",
      " [210.           2.79820919]\n",
      " [211.           3.26539755]\n",
      " [212.           3.60778809]\n",
      " [213.           2.72049904]\n",
      " [214.           3.04393649]\n",
      " [215.           2.77267671]\n",
      " [216.           2.66089439]\n",
      " [217.           2.58777881]\n",
      " [218.           2.84258723]\n",
      " [219.           3.1044569 ]\n",
      " [220.           2.72914004]\n",
      " [221.           2.72949457]\n",
      " [222.           2.92162633]\n",
      " [223.           3.06032443]\n",
      " [224.           2.5224402 ]\n",
      " [225.           2.86546993]\n",
      " [226.           2.82467461]\n",
      " [227.           2.6687355 ]]\n"
     ]
    }
   ],
   "source": [
    "print((y_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
